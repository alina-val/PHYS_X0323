{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Representation and Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real numbers are stored with a decimal precision (or mantissa) and the decimal exponent range. The mantissa contains the significant figures of the number (and thereby the precision of the number). A number like (9.90625)10 in the decimal representation is given in a binary representation by\n",
    "\n",
    "(1001.11101)$_2$ = $1\\times2^3 +0\\times2^2 +0\\times2^1 +1\\times2^0 +1\\times2^{−1} +1\\times2^{−2} +1\\times2^{−3} +0\\times2^{−4} +1 \\times 2^{−5}$\n",
    "\n",
    "and it has an exact machine number representation since we need a finite number of bits to represent this number. This representation is however not very practical. Rather, we prefer to use a scientific notation. In the decimal system we would write a number like 9.90625 in what is called the normalized scientific notation. This means simply that the decimal point is shifted and appropriate powers of 10 are supplied. Our number could then be written as\n",
    "$9.90625 = 0.990625 \\times 10^1$,\n",
    "and a real non-zero number could be generalized as\n",
    "$x = \\pm r \\times 10^n$,\n",
    "with a $r$ a number in the range $1/10 \\le r < 1$. In a similar way we can represent a binary number in\n",
    "scientific notation as\n",
    "$x = \\pm q \\times 2^m$,\n",
    "with a $q$ a number in the range $1/2 \\le q < 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a typical computer, floating-point numbers are represented in the way described above, but with certain restrictions on q and m imposed by the available word length. In the machine, our number x is represented as\n",
    "\n",
    "$x = (−1)^s \\times mantissa \\times 2^{exponent}$\n",
    "\n",
    "where $s$ is the sign bit, and the exponent gives the available range. With a single-precision word, 32 bits, 8 bits would typically be reserved for the exponent, 1 bit for the sign and 23 for the mantissa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32-bit – single precision:\n",
    "\n",
    "Sign bit: 1 bit\n",
    "\n",
    "Exponent: 8 bits\n",
    "\n",
    "Significand precision: 24 bits (23 explicitly stored)\n",
    "\n",
    "This gives 6–9 significant decimal digits precision!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 64-bit = double precision:\n",
    "\n",
    "Sign bit: 1 bit\n",
    "\n",
    "Exponent: 11 bits\n",
    "\n",
    "Significand precision: 53 bits (52 explicitly stored)\n",
    "\n",
    "This gives 15–17 significant decimal digits precision.\n",
    "This the the Python default standard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 128-bit = quadruple precision:\n",
    "\n",
    "Sign bit: 1 bit\n",
    "\n",
    "Exponent: 15 bits\n",
    "\n",
    "Significand precision: 113 bits (112 explicitly stored)\n",
    "\n",
    "This gives 33–36 significant decimal digits precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 256-bit – Octuple precision:\n",
    "\n",
    "Sign bit: 1 bit\n",
    "    \n",
    "Exponent: 19 bits\n",
    "    \n",
    "Significand precision: 237 bits (236 explicitly stored)\n",
    "\n",
    "THIS IS RARELY IMPLEMENTED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important consequence of rounding error is that you should **NEVER Use an if statment to test equality of two floats.**  For instance, you should nerev, in any program, have a statment like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if x == 3.3:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to do a logic trigger based on a float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-12\n",
    "if abs(x-3.3) < epsilon:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which operations are most important in dealing with precision?\n",
    "\n",
    "__Subtraction__ and __Derivatives__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtraction\n",
    "\n",
    "a = b - c\n",
    "\n",
    "We have:   $fl(a) = fl(b) - fl(c) = a(1+\\epsilon_a)$  or\n",
    "            $fl(a) = b(1+\\epsilon_b) - c(1+\\epsilon_c)$\n",
    "            \n",
    "So, $fl(a)/a = 1 + \\epsilon_b (b/a) - \\epsilon_c (c/a)$\n",
    "\n",
    "IF $b \\sim c$, we have the potential of increased error on $fl(a)$\n",
    "\n",
    "\n",
    "If we have:\n",
    "\n",
    "$x = 1000000000000000$\n",
    "\n",
    "$y = 1000000000000001.2345678901234$\n",
    "\n",
    "as far the computer is concerned:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1000000000000000\n",
    "y = 1000000000000001.2345678901234\n",
    " \n",
    "print(y-x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The true result should be 1.2345678901234!**\n",
    "\n",
    "In other words, instead of 16-figure accuracy we now only have three figures and the fractional error is a few percent of the true value.  This is much worse than before!\n",
    "\n",
    "\n",
    "To see another exanple of this in practice, consider two numbers:\n",
    "\n",
    "$x = 1$, and $ y = 1+10^{-14}\\sqrt 2$ \n",
    "\n",
    "Simply we can see that:\n",
    "\n",
    "$ 10^{14} (y - x) = \\sqrt 2$\n",
    "\n",
    "Let us try the same calculation in python:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "x = 1.0\n",
    "y = 1.0 + (1e-14)*sqrt(2)\n",
    "\n",
    "print((1e14)*(y-x))\n",
    "print(sqrt(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again error off by a percent.  We need to be careful in how we code math!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1:  Summing $1/n$ \n",
    "\n",
    "Consider the series:\n",
    "\n",
    "$$s_1 = \\sum_{n=1}^N \\frac{1}{n}$$ which is finite when N is finite, then consider\n",
    "\n",
    "$$s_2 = \\sum_{n=N}^1 \\frac{1}{n}$$ which when summed analyitically should give $s_2 = s_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.997896413852555\n",
      "18.997896413851233\n"
     ]
    }
   ],
   "source": [
    "# Write a code to perform both of these to sums for N = 1e8 and compare\n",
    "import numpy as np\n",
    "N = 1e8\n",
    "s1 = 1\n",
    "s2 = 1\n",
    "for n in np.arange(2, N+1):\n",
    "    s1 = s1 + (1/n)\n",
    "print(s1)\n",
    "for m in np.arange(N, 1, -1):\n",
    "    s2 = s2 + (1/m)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: $e^{-x}$\n",
    "\n",
    "There are three possible algorithms for $e^{-x}$\n",
    "\n",
    "1) Simple: $$e^{-x} = \\sum_{n=0}^{\\infty} (-1)^n \\; \\frac{x^n}{n!}$$  \n",
    "\n",
    "2) Recursion: $$e^{-x} = \\sum_{n=0}^{\\infty} s_n = \\sum_{n=0}^{\\infty} (-1)^n \\; \\frac{x^n}{n!}$$  where $$ s_n = -s_{n-1} \\frac{x}{n}$$\n",
    "\n",
    "3) Inverse:  $$e^{x} = {\\sum_{n=0}^{\\infty} \\frac{x^n}{n!}}$$  Then take the inverse:   $$e^{-x} = \\frac{1}{e^{x}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0      1.0      1.0      1.0\n",
      "10.0 4.539992943360908e-05      4.539992967040021e-05      4.539992976248486e-05      4.5399929762484854e-05\n",
      "20.0 1.3081483199294182e-09      6.147561828914626e-09      2.0611536224385583e-09      2.061153622438558e-09\n",
      "30.0 -6.013867356706994e-05      6.102999924256412e-06      9.357622968840171e-14      9.357622968840175e-14\n",
      "40.0 -117.35890501433573      -122.92837117256363      4.248354255291594e-18      4.248354255291589e-18\n",
      "50.0 -564767318538.3699      -564767266924.6326      1.9287498485811295e-22      1.9287498479639178e-22\n",
      "60.0 -4.385497375692056e+19      -4.385497375563963e+19      8.756523735728401e-27      8.75651076269652e-27\n",
      "70.0 -2.0436358336031848e+26      -2.043635833603175e+26      3.977161397179805e-31      3.975449735908647e-31\n",
      "80.0 -1.2156134999799277e+32      -1.2156134999799248e+32      1.8362668153382486e-35      1.8048513878454153e-35\n",
      "90.0 -1.501680189658279e+37      -1.5016801896582833e+37      9.734161245088653e-40      8.194012623990515e-40\n",
      "100.0 -5.37097871746855e+41      -5.3709787174685515e+41      7.643449333734118e-44      3.720075976020836e-44\n"
     ]
    }
   ],
   "source": [
    "# write a function to compute e^-X for all three methods \n",
    "# Then chack their output for x = 0 - 100, in steps of 10 and \n",
    "# Compare to the numpy version of exp(-x) which is imported above. \n",
    "import numpy as np\n",
    "import math\n",
    "N = 100\n",
    "\n",
    "for k in np.arange(0, 110, 10, dtype=numpy.float64):\n",
    "   \n",
    "    def e_minusx_simple(x):\n",
    "        emxsmp = 1\n",
    "        for n in np.arange(1, N):\n",
    "            emxsmp = emxsmp + ((((-1)**n)*(x**n))/(math.factorial(n)))    \n",
    "        return emxsmp\n",
    "    e_minusx_simple(k)\n",
    "    \n",
    "    def e_minusx_recurse(x):\n",
    "        emxrec = 0\n",
    "        for n in np.arange(0, N):\n",
    "            def s(n):\n",
    "                if n == 0:\n",
    "                    return 1\n",
    "                else:\n",
    "                    f = (-1)*(x/n)*s(n-1)\n",
    "                    return f\n",
    "            emxrec = emxrec + s(n)\n",
    "        return emxrec\n",
    "    e_minusx_recurse(k)\n",
    "\n",
    "    def e_minusx_inverse(x):\n",
    "        emx = 1\n",
    "        for n in np.arange(1, N):\n",
    "            emx = emx + ((x**n)/(math.factorial(n)))\n",
    "        emxinv = 1/emx\n",
    "        return emxinv\n",
    "    e_minusx_inverse(k)\n",
    "    \n",
    "    print(k, e_minusx_simple(k), '    ', e_minusx_recurse(k), '    ',e_minusx_inverse(k), '    ', np.exp(-k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
